{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from graphviz import Digraph\n",
    "import math\n",
    "\n",
    "logging.basicConfig(filename='./log.txt',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_bipolar(x):\n",
    "    return sigmoid_binary(x) - 0.5\n",
    "def sigmoid_binary(x):\n",
    "    return  1/(1 + math.e**(-x))\n",
    "def relu(x):\n",
    "    logging.debug(\"Relu({}) Called: returning {}\".format(x,max(x,0)))\n",
    "    return max(0,x)\n",
    "\n",
    "def identity(x):\n",
    "    logging.debug(\"Identity({}) Called: returning {}\".format(x,x))\n",
    "    return x\n",
    "\n",
    "def step(x,theta):\n",
    "    ret = 0\n",
    "    if x > theta:\n",
    "        ret = 1\n",
    "    elif x < theta:\n",
    "        ret = -1\n",
    "    else:\n",
    "        ret = 0\n",
    "    logging.debug(\"Step({},{}) Called: returning {}\".format(x,theta,ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "\n",
    "    def __init__(self, num_nodes, next_num_nodes = 1, initial_weight = None, is_last = False, has_bias = False, actn_fxn = relu):\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.actn_fxn  = actn_fxn\n",
    "        self.next_num_nodes = next_num_nodes\n",
    "        self.is_last = is_last\n",
    "        self.weight_matrix = None\n",
    "        self.has_bias = has_bias\n",
    "\n",
    "        #cannot have a bias in output layer\n",
    "        if self.has_bias and self.is_last:\n",
    "            logging.critical(\"An output layer cannot have a bias. Cannot Continue\")\n",
    "            exit()\n",
    "        \n",
    "        #cannot have a bias only in a layer (it doesn't make sense)\n",
    "        if self.has_bias and self.num_nodes == 1:\n",
    "            logging.critical(\"A layer cannot have only one node that is a bias\")\n",
    "            exit()\n",
    "        \n",
    "        logging.debug(\"layer object initialized with \\n\\tNumber of nodes: {}\\n\\tActivation Function: {}\\n\\tNext Number of Nodes: {}\\n\\tIs Last: {}\\n\".format(self.num_nodes,self.actn_fxn,self.next_num_nodes,self.is_last))\n",
    "        \n",
    "        if initial_weight is None:\n",
    "            logging.debug('Using default values for the weight matrix')\n",
    "            self.weight_matrix = np.zeros([self.num_nodes, self.next_num_nodes],dtype=float)\n",
    "\n",
    "        elif isinstance(initial_weight, (int,float)):\n",
    "            logging.debug(\"Using the weight value for all weights in the layer\")\n",
    "            self.weight_matrix = (np.zeros(shape = (self.num_nodes, self.next_num_nodes),dtype=float))\n",
    "            self.weight_matrix.fill(float(initial_weight))\n",
    "\n",
    "        elif initial_weight.shape == (self.num_nodes, self.next_num_nodes):\n",
    "            logging.debug(\"Using user provided values\")\n",
    "            self.weight_matrix = np.array(initial_weight, dtype = float)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            logging.warning('Weight matrix provided is of incompatible size. Using default values')\n",
    "            self.weight_matrix = np.zeros(shape = (self.num_nodes,self.next_num_nodes),dtype = float)\n",
    "\n",
    "        self.input_vector = None\n",
    "\n",
    "    def send(self, input_vector):\n",
    "\n",
    "        #flattened to keep things simple\n",
    "        input_vector = np.array(input_vector).flatten()\n",
    "\n",
    "        suppossed_input_vector_size = self.num_nodes\n",
    "        \n",
    "        if self.has_bias:\n",
    "            suppossed_input_vector_size -= 1\n",
    "            \n",
    "        if input_vector.shape != (suppossed_input_vector_size,):\n",
    "            logging.critical(\"Input vector not of desired size. Cannot continue!\")\n",
    "            return None\n",
    "\n",
    "        temp = []\n",
    "        if self.has_bias:\n",
    "            temp.append(1)\n",
    "        \n",
    "        for i in input_vector:\n",
    "            temp.append(self.actn_fxn(i))\n",
    "        self.input_vector = np.asarray([ self.actn_fxn(i) for i in input_vector ])\n",
    "\n",
    "        return self.input_vector\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        if self.input_vector is None:\n",
    "            logging.critical(\"Input not yet provided. Cannot continue!\")\n",
    "            return None\n",
    "\n",
    "        if self.is_last:\n",
    "            return self.input_vector\n",
    "\n",
    "        #the input is required to be in a row only\n",
    "        temp_input_matrix = np.reshape(self.input_vector, newshape=(1,self.num_nodes))\n",
    "\n",
    "        #input is consumed\n",
    "        self.input_vector = None\n",
    "\n",
    "        output_matrix = np.dot(temp_input_matrix,self.weight_matrix)\n",
    "\n",
    "        return output_matrix.flatten()\n",
    "\n",
    "\n",
    "    def desc(self):\n",
    "        print(\"Number of Nodes: {}\\n Number of Nodes in next layer: {}\\nWeights:\\n {}\\n\"\n",
    "               .format(self.num_nodes, self.next_num_nodes,self.weight_matrix))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class n_ff_network:\n",
    "\n",
    "    def __init__(self, ff_layers, initial_weights = None, has_bias = None,actn_fxn = relu):\n",
    "\n",
    "        self.ff_layers = list(np.array(ff_layers).flatten())\n",
    "        self.num_layers = len(self.ff_layers)\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            logging.critical('Neural Network cannot have less than two layers. Cannot Continue')\n",
    "            exit()\n",
    "        \n",
    "        self.n_layers = []\n",
    "        \n",
    "        if has_bias is None:\n",
    "            has_bias = [False for i in range(self.num_layers-1)]\n",
    "        elif np.asarray(has_bias).flatten().shape != (self.num_layers-1,):\n",
    "            logging.warning('has_bias is not of compatible size. Using default value')\n",
    "            has_bias = [False for i in range(self.num_layers-1)]\n",
    "        \n",
    "        if isinstance(initial_weights,(type(None),int,float)):\n",
    "            self.n_layers = [ layer(num_nodes = self.ff_layers[i], next_num_nodes= self.ff_layers[i+1],\n",
    "                                    actn_fxn = actn_fxn, initial_weight= initial_weights, has_bias = has_bias[i])\n",
    "                               for i in range(self.num_layers - 1)]\n",
    "\n",
    "        elif initial_weights.shape[0] == self.num_layers - 1:\n",
    "            self.n_layers = [ layer(num_nodes = self.ff_layers[i], next_num_nodes= self.ff_layers[i+1],\n",
    "                                    actn_fxn = actn_fxn, initial_weight= initial_weights[i], has_bias = has_bias[i])\n",
    "                               for i in range(self.num_layers - 1)]\n",
    "\n",
    "        self.n_layers.append(layer(num_nodes = self.ff_layers[self.num_layers-1],initial_weight=1,\n",
    "                                       next_num_nodes=self.ff_layers[self.num_layers-1], actn_fxn = actn_fxn, is_last = True,\n",
    "                                  has_bias = False))\n",
    "\n",
    "        self.n_layers[0].actn_fxn = identity\n",
    "        self.input_vector = None\n",
    "        self.output_vector = None\n",
    "        \n",
    "        #default learning algos\n",
    "        self.learning_algos = {}\n",
    "        self.learning_algos['hebb'] = self.hebb_learn\n",
    "        #self.learning_algos['perceptron'] = self.perceptron_learn\n",
    "        #self.learning_algos['delta'] = self.delta_learn\n",
    "        #self.learning_algos['backprop'] = self.backprop\n",
    "\n",
    "    def send(self, input_vector):\n",
    "        \n",
    "        #checking if the input layer of neural network accepts the input_vector as a valid input vector\n",
    "        return_val = self.n_layers[0].send(input_vector)\n",
    "        \n",
    "        if return_val is None:\n",
    "            logging.critical('Input_vector incompatible. Cannot continue')\n",
    "            return None;\n",
    "        \n",
    "        #flattened to keep things simple\n",
    "        self.input_vector = np.array(input_vector).flatten()\n",
    "        \n",
    "        return self.input_vector\n",
    "    \n",
    "    def generate(self):\n",
    "\n",
    "        curr_input = self.input_vector\n",
    "\n",
    "        count = 0\n",
    "        for i in self.n_layers:\n",
    "            count +=1\n",
    "            i.send(curr_input)\n",
    "            curr_input = i.generate()\n",
    "\n",
    "        self.output_vector = curr_input\n",
    "\n",
    "        return self.output_vector\n",
    "\n",
    "    def desc(self):\n",
    "        for i in range(self.num_layers):\n",
    "            print(\"Layer {}\\n\".format(i+1))\n",
    "            self.n_layers[i].desc()\n",
    "\n",
    "    def show_network(self,comment=\"Neural Network\"):\n",
    "        dot = Digraph(comment)\n",
    "\n",
    "        \n",
    "        #legend\n",
    "        dot.attr(rankdir='LR',ranksep='4')\n",
    "        dot.node(name=\"input_layer\", rank = 'sink',xlabel=\"Input Layer\",label=\"\", fontsize = '12',style=\"filled\",color=\"green\",fixedsize = 'true', shape=\"square\",width=\"0.1\")\n",
    "        dot.node(name=\"output_layer\", xlabel=\"Output Layer\",label=\"\", fontsize = '12',style=\"filled\",color=\"red\",fixedsize = 'true', shape=\"square\",width=\"0.1\")\n",
    "        dot.node(name=\"hidden_layers\", xlabel=\"Hidden Layers\",label=\"\", fontsize = '12',style=\"filled\",color=\"grey\",fixedsize = 'true', shape=\"square\",width=\"0.1\")\n",
    "        \n",
    "        start = 0\n",
    "        for i in range(self.num_layers):\n",
    "            color = \"grey\"\n",
    "            if i == 0:\n",
    "                color = \"green\"\n",
    "            elif i == self.num_layers - 1:\n",
    "                color = \"red\"\n",
    "                \n",
    "            with dot.subgraph(name = 'cluster_'+str(i)) as subdot:\n",
    "                for j in range(self.n_layers[i].num_nodes):\n",
    "                    label_name = 'x' + str(i) + str(j)\n",
    "                    if self.n_layers[i].has_bias and j == 0:\n",
    "                        label_name = '1'\n",
    "                \n",
    "                    subdot.node(name = str(start),label = label_name,color=color, style=\"filled\",rankdir='TB')\n",
    "                    start +=1\n",
    "\n",
    "        start = 0\n",
    "        for i in range(self.num_layers-1):\n",
    "            curr_layer = self.n_layers[i]\n",
    "            next_start = start + curr_layer.num_nodes\n",
    "\n",
    "            tail = start\n",
    "            head = next_start\n",
    "            for j in range(curr_layer.num_nodes):\n",
    "                head = next_start\n",
    "                for k in range(curr_layer.next_num_nodes):\n",
    "                    dot.edge(tail_name = str(tail),head_name = str(head), label = str(curr_layer.weight_matrix[j][k]))\n",
    "                    head += 1\n",
    "                tail += 1\n",
    "\n",
    "            start = next_start\n",
    "\n",
    "        #dot.render('./'+comment+'.png', view = True)\n",
    "        dot.view()\n",
    "        \n",
    "    def hebb_learn(self,arg_dict):\n",
    "        output_vector = arg_dict['output_vector']\n",
    "        \n",
    "        #hebb only works when there are no hidden layers\n",
    "        if self.num_layers > 2:\n",
    "            logging.critical('Hebb cannot work with any hidden layers. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        input_layer = self.n_layers[0]\n",
    "        for i in range(len(output_vector)):\n",
    "            output = output_vector[i]\n",
    "            for j in range(input_layer.num_nodes):\n",
    "                input_layer.weight_matrix[j][i] += output*self.input_vector[j]\n",
    "        \n",
    "        \n",
    "    def learn(self, learning_algo: str, input_matrix, output_matrix, epochs = 1, **xargs):\n",
    "        \n",
    "        if learning_algo not in self.learning_algos.keys():\n",
    "            logging.critical('{} learning algorithm is not recoginized. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        input_matrix = np.array(input_matrix)\n",
    "        output_matrix = np.array(output_matrix)\n",
    "        \n",
    "        if len(input_matrix.shape) != 2 or len(output_matrix.shape) != 2:\n",
    "            logging.critical('Input and Output matrices should have only two dimensions. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        if input_matrix.shape[0] != output_matrix.shape[0]:\n",
    "            logging.critical('Input and Output matrices have incompatible dimensions. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        input_layer = self.n_layers[0]\n",
    "        output_layer = self.n_layers[self.num_layers-1]\n",
    "        \n",
    "        num_pairs = input_matrix.shape[0]\n",
    "        \n",
    "        if num_pairs < 1:\n",
    "            logging.critical('No input provided. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        if input_layer.send(input_matrix[0]) is None:\n",
    "            logging.critical('Input Matrix dimensions` incompatible. Cannot Continue')\n",
    "            return None\n",
    "        \n",
    "        if output_layer.send(output_matrix[0]) is None:\n",
    "            logging.critical('Output Matrix dimensions` incompatible. Cannot Continue')\n",
    "            \n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for j in range(num_pairs):\n",
    "                self.send(input_matrix[j].flatten())\n",
    "                self.generate()\n",
    "                xargs['output_vector'] = output_matrix[j].flatten()\n",
    "                self.learning_algos[learning_algo](xargs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = n_ff_network([3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called hebb\n",
      "called hebb\n",
      "called hebb\n",
      "called hebb\n"
     ]
    }
   ],
   "source": [
    "def transform_bipolar(val : list) -> list:                                      \n",
    "    ans = []                                                                    \n",
    "    for i in val:                                                               \n",
    "        if i:                                                                   \n",
    "            ans.append(1)                                                       \n",
    "        else:                                                                   \n",
    "            ans.append(-1)                                                      \n",
    "    return ans                                                                  \n",
    "                                                                                \n",
    "                                                                                \n",
    "                                                                                \n",
    "def generate(func):                                                             \n",
    "                                                                                \n",
    "    input_v = []                                                                \n",
    "    output_v = []                                                               \n",
    "                                                                                \n",
    "    x = True                                                                    \n",
    "    y = True                                                                    \n",
    "                                                                                \n",
    "    func = func.lower()                                                         \n",
    "                                                                                \n",
    "    for i in range(4):                                                          \n",
    "                                                                                \n",
    "        if func == 'and':                                                       \n",
    "            t = x and y                                                         \n",
    "        elif func == 'nand':                                                    \n",
    "            t = not (x and y)                                                   \n",
    "        elif func == 'or':                                                      \n",
    "            t = x or y                                                          \n",
    "        elif func == 'nor':                                                     \n",
    "            t = not ( x or y )                                                  \n",
    "                                                                                \n",
    "        else:                                                                   \n",
    "            raise Exception('not defined')                                      \n",
    "                                                                                \n",
    "        input_v.append(transform_bipolar([x,y,True]))                           \n",
    "        output_v.append(transform_bipolar([t]))                                 \n",
    "                                                                                \n",
    "        if not y:                                                               \n",
    "            x = not x                                                           \n",
    "        y = not y                                                               \n",
    "                                                                                \n",
    "                                                                                \n",
    "    return input_v, output_v                                                    \n",
    "\n",
    "network.show_network()\n",
    "input_matrix, output_matrix = generate('and')\n",
    "network.learn('hebb',input_matrix, output_matrix)\n",
    "network.show_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1+False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.node(\"kame\",label=\"hame\",fill=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:An output layer cannot have a bias. Cannot Continue\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n",
      "CRITICAL:root:A layer cannot have only one node that is a bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open('./log.txt')\n",
    "for i in file:\n",
    "    if \"CRITICAL\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a,b,c):\n",
    "    return a+b+c\n",
    "def sub(b,a):\n",
    "    return a-b\n",
    "def calc(opr:str, x=3, **args):\n",
    "    print(args)\n",
    "    print(**args)\n",
    "    if opr == 'add':\n",
    "        return add(args)\n",
    "    else:\n",
    "        return sub(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 3}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'a' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-aee902d2bb83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sub'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-cb5e7785d772>\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(opr, x, **args)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'a' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "calc('sub',x =2, a= 1, b  = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(len(a.shape))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
